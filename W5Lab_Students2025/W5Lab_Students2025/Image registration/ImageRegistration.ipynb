{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a3cc37f-1343-4f53-8378-ff72b043567e",
   "metadata": {},
   "source": [
    "# Image Registration\n",
    "\n",
    "Image registration is a critical topic in computer vision, especially for aligning images taken at different times, from different viewpoints, or by different sensors.\n",
    "\n",
    "You will work on an image registration problem based on landmark-based rigid registration. This allows you to understand the relationship between the transformation matrix, point correspondences, and the final warped image.\n",
    "\n",
    "This exercise requires students to find the 3x3 rigid transformation matrix that maps corresponding points from a \"moving\" image to a \"fixed\" (target) image.\n",
    "\n",
    "## Task 1. Define Corresponding Landmarks\n",
    "You will manually select a minimum of two corresponding point pairs from the Moving Image and the Fixed Image.\n",
    "Select Points: Use a tool (like a simple mouse click function or hardcoded coordinates for simplicity) to define corresponding points:$\\mathbf{P} = [(x_{p1}, y_{p1}), (x_{p2}, y_{p2}), \\dots]$ (Points in Moving Image)$\\mathbf{Q} = [(x_{q1}, y_{q1}), (x_{q2}, y_{q2}), \\dots]$ (Corresponding points in Fixed Image). To solve for a rigid transformation (rotation and translation), a minimum of two non-collinear point pairs is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868aa469-1de6-4ffb-8917-5bc59f1ff727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.transform import estimate_transform\n",
    "from cv2 import warpAffine\n",
    "\n",
    "\n",
    "# --- EXECUTE POINT SELECTION ---\n",
    "# Assuming img_fixed and img_moving are loaded [0, 1] images\n",
    "\n",
    "img_fixed = skimage.io.imread('mri2_fixed.jpg', as_gray=True)\n",
    "img_moving = skimage.io.imread('mri2_moving.jpg', as_gray=True)\n",
    "\n",
    "# --- Check the image mri2_fixed_landmarks.jpg and define the four points for P \n",
    "# P = np.array([[1, 2], [3, 4]]) \n",
    "# --- Open mri2_moving.jpg and look for the corresponding points and store them Q\n",
    "# Q = np.array([[111, 96], [96, 111]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515e073-7db6-48c2-8fd5-7c8a583703d9",
   "metadata": {},
   "source": [
    "## Task 2: Formulate and Solve the Linear System\n",
    "\n",
    "The goal is to find the transformation parameters ($\\theta, t_x, t_y$) embedded within the $3 \\times 3$ transformation matrix $\\mathbf{T}$. Since we have multiple points, we can set up a system of linear equations to find the parameters that minimize the error.HINT: A 2D rigid transformation from $\\mathbf{p} = (x, y)$ to $\\mathbf{q} = (x', y')$ can be written as:$$\\begin{aligned}\n",
    "x' &= x \\cos\\theta - y \\sin\\theta + t_x \\\\\n",
    "y' &= x \\sin\\theta + y \\cos\\theta + t_y\n",
    "\\end{aligned}$$You can use the function skimage.transform.estimate_transform('rigid', P, Q)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96f9d82-ac21-46bf-bcc0-e832e3271525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# -----------------\n",
    "# 2.1. YOUR CODE HERE: Estimate the Rigid Transformation\n",
    "# -----------------\n",
    "# You can use the function 'estimate_transform()' with the corresponding parameter for rigid transformations\n",
    "\n",
    "# Then, extract the 3x3 Homogeneous Matrix\n",
    "# T_matrix = tform.params\n",
    "# print(\"Transformation Matrix T:\\n\", T_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7beab-b9d1-4e61-aa7d-c8f1e16c2fea",
   "metadata": {},
   "source": [
    "## Task 3: Apply Inverse Warping\n",
    "The final step is to apply the transformation to the entire image using inverse warping (backward mapping). This requires the inverse of the transformation matrix, $\\mathbf{T}^{-1}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358bf52-e7bc-420a-aa3a-85d01278d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Assume 'img_moving' is the source image.\n",
    "\n",
    "# -----------------\n",
    "# 3.1. YOUR CODE HERE: Calculate the Inverse Transformation Matrix\n",
    "# -----------------\n",
    "# You can use the function 'np.linalg.inv()'\n",
    "\n",
    "# 3.2. YOUR CODE HERE: Apply the Inverse Affine Transform (Registration)\n",
    "# We use openCV's warpAffine() function for better performance. It takes\n",
    "# - the moving image\n",
    "# - the upper 2x3 part of the inverse transformation matrix\n",
    "# - the output size as (width, height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876f27c-577a-49a6-859a-6413c8ffdd33",
   "metadata": {},
   "source": [
    "###  (Optional) Calculate Error- Root Mean Square Error (RMSE) \n",
    "The RMSE is a normalized version of the SSD, which is easier to interpret as it gives the \"average\" magnitude of the error per pixel in the original intensity units.$$RMSE = \\sqrt{\\frac{1}{N} \\sum_{y} \\sum_{x} [I_F(x, y) - I_R(x, y)]^2}$$Interpretation: RMSE gives you the average difference between corresponding pixels. If the images are 8-bit (0-255), an RMSE of 10 means the average pixel difference is 10 intensity units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93196e31-7203-4f7a-84fe-ec60a0becfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3. Calculate the Root Mean Square Error (RMSE), which is the Euclidean distance between the two images, normalized by the number of pixels.\n",
    "# Calculate the squared difference at every pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d5a33-6c77-45b8-944c-83e6c84830b0",
   "metadata": {},
   "source": [
    "## Task 4: Visualization (Image Fusion)\n",
    "Visualize the quality of the registration.\n",
    "Display the fixed image, registered image, and the combination of the registered image with the fixed image using the function 'blend_images()' below. If alignment is perfect, the fused image should look clean and sharp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497b03b-7270-4de2-8076-eaf9731b78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Display Code (Do Not Modify) ---\n",
    "# Create a checkerboard or blended image to show alignment quality\n",
    "def blend_images(img1, img2):\n",
    "    # Overlay the registered image (green) onto the fixed image (red)\n",
    "    blended = np.stack([img1, img2, img1 / 2 + img2 / 2], axis=-1)\n",
    "    return np.clip(blended, 0, 1)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Fixed Image (Target)')\n",
    "plt.imshow(img_fixed, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Registered Image (Source)')\n",
    "plt.imshow(img_registered, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Fixed vs. Registered (Blended)')\n",
    "plt.imshow(blend_images(img_fixed.astype(np.float64)/255, img_registered.astype(np.float64)/255))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e81e5-b237-433a-a53b-094289658163",
   "metadata": {},
   "source": [
    "**QUESTION : Display the fixed, moving, and registered images in the report. If you calculated the RMSE, include it.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
